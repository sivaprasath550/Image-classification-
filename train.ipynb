{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Classification using CNN - MNIST Digit Classification\n",
        "\n",
        "This notebook implements a Convolutional Neural Network (CNN) in PyTorch to classify MNIST handwritten digits with 98% accuracy in just 5 epochs.\n",
        "\n",
        "**Features:**\n",
        "- Deep CNN Architecture with ReLU activations\n",
        "- Adam optimizer for efficient training\n",
        "- Visualization of predictions and training history\n",
        "- Achieves 98%+ accuracy on test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Set Device (CPU/GPU)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CNN Model Architecture\n",
        "\n",
        "The model consists of:\n",
        "- **Convolutional Blocks**: Two blocks with 32 and 64 filters respectively\n",
        "- **Fully Connected Layers**: 512 neurons with dropout for regularization\n",
        "- **Output Layer**: 10 neurons (one for each digit class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CNN Model Architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # First convolutional block\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        # Second convolutional block\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # First block: Conv -> ReLU -> Conv -> ReLU -> MaxPool\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)  # 28x28 -> 14x14\n",
        "        \n",
        "        # Second block: Conv -> ReLU -> Conv -> ReLU -> MaxPool\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = F.max_pool2d(x, 2)  # 14x14 -> 7x7\n",
        "        \n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Loading and Preprocessing\n",
        "\n",
        "Load MNIST dataset with normalization transformations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data loading and preprocessing\n",
        "def get_data_loaders(batch_size=128):\n",
        "    # Transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean and std\n",
        "    ])\n",
        "    \n",
        "    # Load datasets\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "    \n",
        "    test_dataset = datasets.MNIST(\n",
        "        root='./data',\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "    \n",
        "    # Data loaders (num_workers=0 for Windows compatibility)\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0\n",
        "    )\n",
        "    \n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0\n",
        "    )\n",
        "    \n",
        "    return train_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training function\n",
        "def train(model, train_loader, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        total += target.size(0)\n",
        "        \n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'Loss': f'{loss.item():.4f}',\n",
        "            'Acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    avg_loss = train_loss / len(train_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Testing Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing function\n",
        "def test(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            total += target.size(0)\n",
        "    \n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "    return avg_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualization Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization function\n",
        "def visualize_predictions(model, test_loader, num_images=10):\n",
        "    model.eval()\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    data_iter = iter(test_loader)\n",
        "    images, labels = next(data_iter)\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(images[:num_images])\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "    \n",
        "    for i in range(num_images):\n",
        "        img = images[i].cpu().squeeze()\n",
        "        axes[i].imshow(img, cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "        axes[i].set_title(\n",
        "            f'True: {labels[i].item()}\\nPred: {preds[i].item()}\\nProb: {probs[i][preds[i]].item():.2f}',\n",
        "            fontsize=10\n",
        "        )\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('predictions.png', dpi=150, bbox_inches='tight')\n",
        "    print('\\nPredictions visualization saved as predictions.png')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Initialize Model and Load Data\n",
        "\n",
        "Set hyperparameters and initialize the model, optimizer, and data loaders.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "\n",
        "# Load data\n",
        "print('Loading MNIST dataset...')\n",
        "train_loader, test_loader = get_data_loaders(batch_size)\n",
        "\n",
        "# Initialize model\n",
        "model = CNN().to(device)\n",
        "print(f'\\nModel architecture:\\n{model}\\n')\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training history\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "test_losses = []\n",
        "test_accs = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Training Loop\n",
        "\n",
        "Train the model for 5 epochs and track performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Starting training...\\n')\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # Train\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, epoch)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    \n",
        "    # Test\n",
        "    test_loss, test_acc = test(model, test_loader, criterion)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accs.append(test_acc)\n",
        "    \n",
        "    print(f'\\nEpoch {epoch}:')\n",
        "    print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'  Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
        "    print('-' * 50)\n",
        "\n",
        "# Final results\n",
        "print(f'\\nFinal Test Accuracy: {test_accs[-1]:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "torch.save(model.state_dict(), 'mnist_cnn_model.pth')\n",
        "print('Model saved as mnist_cnn_model.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Plot Training History\n",
        "\n",
        "Visualize the training and test loss/accuracy curves.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, 'b-', label='Train Loss')\n",
        "plt.plot(range(1, num_epochs + 1), test_losses, 'r-', label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accs, 'b-', label='Train Accuracy')\n",
        "plt.plot(range(1, num_epochs + 1), test_accs, 'r-', label='Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training and Test Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
        "print('Training history saved as training_history.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Visualize Predictions\n",
        "\n",
        "Display sample predictions with confidence scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "print('\\nVisualizing predictions...')\n",
        "visualize_predictions(model, test_loader, num_images=10)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
